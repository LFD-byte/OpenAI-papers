# OpenAI-papers

## 2024

* Measuring short-form factuality in large language models [[pdf]](https://arxiv.org/abs/2411.04368) [[code]](https://github.com/openai/simple-evals)
* Simplifying, Stabilizing and Scaling Continuous-Time Consistency Models [[pdf]](https://arxiv.org/abs/2410.11081)
* First-Person Fairness in Chatbots [[pdf]](https://cdn.openai.com/papers/first-person-fairness-in-chatbots.pdf)
* MLE-bench: Evaluating Machine Learning Agents on Machine Learning Engineering [[pdf]](https://arxiv.org/abs/2410.07095) [[code]](https://github.com/openai/mle-bench/)
* Rule Based Rewards for Language Model Safety [[pdf]](https://cdn.openai.com/rule-based-rewards-for-language-model-safety.pdf) [[code]](https://github.com/openai/safety-rbr-code-and-data)
* Prover-Verifier Games improve legibility of LLM outputs [[pdf]](https://arxiv.org/abs/2407.13692)
* A Holistic Approach to Undesired Content Detection in the Real World [[pdf]](https://arxiv.org/abs/2208.03274)
* Improved Techniques for Training Consistency Models [[pdf]](https://arxiv.org/abs/2310.14189)
* Consistency Models [[pdf]](https://arxiv.org/abs/2303.01469) 
* Scaling and evaluating sparse autoencoders [[pdf]](https://arxiv.org/abs/2406.04093) [[code]](https://github.com/openai/sparse_autoencoder)
* The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions [[pdf]](https://arxiv.org/abs/2404.13208) 

## 2023

* Let's Verify Step by Step [[pdf]](https://arxiv.org/abs/2305.20050)
* GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models [[pdf]](https://arxiv.org/abs/2303.10130)
* GPT-4 Technical Report [[pdf]](https://arxiv.org/abs/2303.08774) 

## 2022

* Point-E: A System for Generating 3D Point Clouds from Complex Prompts [[pdf]](https://arxiv.org/abs/2212.08751) [[code]](https://github.com/openai/point-e)
* Scaling Laws for Reward Model Overoptimization [[pdf]](https://arxiv.org/abs/2210.10760) 
* Robust Speech Recognition via Large-Scale Weak Supervision [[pdf]](https://cdn.openai.com/papers/whisper.pdf) [[code]](https://github.com/openai/whisper)
* Efficient Training of Language Models to Fill in the Middle [[pdf]](https://arxiv.org/abs/2207.14255) [[code]](https://github.com/openai/human-eval-infilling?tab=readme-ov-file)
* Video PreTraining (VPT): Learning to Act by Watching Unlabeled Online Videos [[pdf]](https://arxiv.org/abs/2206.11795) [[code]](https://github.com/openai/Video-Pre-Training)
* Evolution through Large Models [[pdf]](https://arxiv.org/abs/2206.08896) 
* Teaching Models to Express Their Uncertainty in Words [[pdf]](https://arxiv.org/abs/2205.14334)
* Hierarchical Text-Conditional Image Generation with CLIP Latents [[pdf]](https://arxiv.org/abs/2204.06125) 
* A Research Agenda for Assessing the Economic Impacts of Code Generation Models [[pdf]](https://cdn.openai.com/papers/Economic_Impacts_Research_Agenda.pdf)
* Formal Mathematics Statement Curriculum Learning [[pdf]](https://arxiv.org/abs/2202.01344)
* Text and Code Embeddings by Contrastive Pre-Training [[pdf]](https://arxiv.org/abs/2201.10005) 

## 2021

* WebGPT: Browser-assisted question-answering with human feedback [[pdf]](https://arxiv.org/abs/2112.09332)
* Training Verifiers to Solve Math Word Problems [[pdf]](https://arxiv.org/abs/2110.14168)
* TruthfulQA: Measuring How Models Mimic Human Falsehoods [[pdf]](https://arxiv.org/abs/2109.07958) [[code]](https://github.com/sylinrl/TruthfulQA)
* Evaluating Large Language Models Trained on Code [[pdf]](https://arxiv.org/abs/2107.03374) 
* Multimodal Neurons in Artificial Neural Networks [[pdf]](https://distill.pub/2021/multimodal-neurons/) [[code]](https://github.com/openai/CLIP-featurevis)
* Understanding the Capabilities, Limitations, and Societal Impact of Large Language Models [[pdf]](https://arxiv.org/abs/2102.02503)
* Learning Transferable Visual Models From Natural Language Supervision [[pdf]](https://arxiv.org/abs/2103.00020) [[code]](https://github.com/openai/CLIP)

## 2020

* Generative Language Modeling for Automated Theorem Proving [[pdf]](https://arxiv.org/abs/2009.03393) 
* Generative Pretraining from Pixels [[pdf]](https://cdn.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pdf) [[code]](https://github.com/openai/image-gpt)
* Language Models are Few-Shot Learners [[pdf]](https://arxiv.org/abs/2005.14165) 
* Measuring the Algorithmic Efficiency of Neural Networks [[pdf]](https://arxiv.org/abs/2005.04305)
* Jukebox: A Generative Model for Music [[pdf]](https://arxiv.org/abs/2005.00341) [[code]](https://github.com/openai/jukebox/)
* Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable Claims [[pdf]](https://arxiv.org/abs/2004.07213)
* Scaling Laws for Neural Language Models [[pdf]](https://arxiv.org/abs/2001.08361)

## 2019

* Dota 2 with Large Scale Deep Reinforcement Learning [[pdf]](https://arxiv.org/abs/1912.06680) 
* Deep Double Descent: Where Bigger Models and More Data Hurt [[pdf]](https://arxiv.org/abs/1912.02292) 
* Leveraging Procedural Generation to Benchmark Reinforcement Learning [[pdf]](https://arxiv.org/abs/1912.01588) [[code]](https://github.com/openai/train-procgen)
* Release Strategies and the Social Impacts of Language Models [[pdf]](https://arxiv.org/abs/1908.09203)
* Solving Rubik's Cube with a Robot Hand [[pdf]](https://arxiv.org/abs/1910.07113) 
* Emergent Tool Use From Multi-Agent Autocurricula [[pdf]](https://arxiv.org/abs/1909.07528) [[code]](https://github.com/openai/multi-agent-emergence-environments)
* Release Strategies and the Social Impacts of Language Models [[pdf]](https://arxiv.org/abs/1908.09203) [[code]](https://github.com/openai/gpt-2)
* Generating Long Sequences with Sparse Transformers [[pdf]](https://arxiv.org/abs/1904.10509) [[code]](https://github.com/openai/sparse_attention)
* Implicit Generation and Generalization in Energy-Based Models [[pdf]](https://arxiv.org/abs/1903.08689) [[code]](https://github.com/openai/ebm_code_release)
* Neural MMO: A Massively Multiagent Game Environment for Training and Evaluating Intelligent Agents [[pdf]](https://arxiv.org/abs/1903.00784) [[code]](https://github.com/openai/neural-mmo)
* Language Models are Unsupervised Multitask Learners [[pdf]](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) [[code]](https://github.com/openai/gpt-2)
* Computational Limitations in Robust Classification and Win-Win Results [[pdf]](https://arxiv.org/abs/1902.01086)

## 2018

* An Empirical Model of Large-Batch Training [[pdf]](https://arxiv.org/pdf/1812.06162)
* Quantifying Generalization in Reinforcement Learning [[pdf]](https://arxiv.org/abs/1812.02341) [[code]](https://github.com/openai/coinrun)
* Concept Learning with Energy-Based Models [[pdf]](https://arxiv.org/abs/1811.02486) 
* Plan Online, Learn Offline: Efficient Learning and Exploration via Model-Based Control [[pdf]](https://arxiv.org/abs/1811.01848)
* Exploration by Random Network Distillation [[pdf]](https://arxiv.org/abs/1810.12894) [[code]](https://github.com/openai/random-network-distillation)
* FFJORD: Free-form Continuous Dynamics for Scalable Reversible Generative Models [[pdf]](https://arxiv.org/abs/1810.01367) 
* Large-Scale Study of Curiosity-Driven Learning [[pdf]](https://arxiv.org/abs/1808.04355) [[code]](https://github.com/openai/large-scale-curiosity)
* Learning Dexterous In-Hand Manipulation [[pdf]](https://arxiv.org/abs/1808.00177)
* Variational Option Discovery Algorithms [[pdf]](https://arxiv.org/abs/1807.10299) 
* Glow: Generative Flow with Invertible 1x1 Convolutions [[pdf]](https://arxiv.org/abs/1807.03039) [[code]](https://github.com/openai/glow)
* Learning Policy Representations in Multiagent Systems [[pdf]](https://arxiv.org/abs/1806.06464) 
* GamePad: A Learning Environment for Theorem Proving [[pdf]][[code]](https://github.com/ml4tp/gamepad)
* Evolved Policy Gradients [[pdf]](https://arxiv.org/abs/1802.04821) [[code]](https://github.com/openai/EPG)
* Gotta Learn Fast: A New Benchmark for Generalization in RL [[pdf]](https://arxiv.org/abs/1804.03720)
* Variance Reduction for Policy Gradient with Action-Dependent Factorized Baselines [[pdf]](https://arxiv.org/abs/1803.07246) 
* Improving GANs Using Optimal Transport [[pdf]](https://arxiv.org/abs/1803.05573)
* On First-Order Meta-Learning Algorithms [[pdf]](https://arxiv.org/abs/1803.02999) [[code]](https://github.com/openai/supervised-reptile)
* Some Considerations on Learning to Explore via Meta-Reinforcement Learning [[pdf]](https://arxiv.org/abs/1803.01118) 
* Multi-Goal Reinforcement Learning: Challenging Robotics Environments and Request for Research [[pdf]](https://arxiv.org/abs/1802.09464) 
* DeepType: Multilingual Entity Linking by Neural Type System Evolution [[pdf]](https://arxiv.org/abs/1802.01021) [[code]](https://github.com/openai/deeptype)

## 2017

* GPU Kernels for Block-Sparse Weights [[pdf]](https://cdn.openai.com/blocksparse/blocksparsepaper.pdf) [[code]](https://github.com/openai/blocksparse)
* Learning Sparse Neural Networks through $L_0$ Regularization [[pdf]](https://arxiv.org/abs/1712.01312) [[code]](https://github.com/AMLab-Amsterdam/L0_regularization)
* Interpretable and Pedagogical Examples [[pdf]](https://arxiv.org/abs/1711.00694) 
* Meta Learning Shared Hierarchies [[pdf]](https://arxiv.org/abs/1710.09767) [[code]](https://github.com/openai/mlsh)
* Sim-to-Real Transfer of Robotic Control with Dynamics Randomization [[pdf]](https://arxiv.org/abs/1710.06537)
* Asymmetric Actor Critic for Image-Based Robot Learning [[pdf]](https://arxiv.org/abs/1710.06542) 
* Domain Randomization and Generative Models for Robotic Grasping [[pdf]](https://arxiv.org/abs/1710.06425) 
* Continuous Adaptation via Meta-Learning in Nonstationary and Competitive Environments [[pdf]](https://arxiv.org/abs/1710.03641) [[code]](https://github.com/openai/robosumo)
* Emergent Complexity via Multi-Agent Competition [[pdf]](https://arxiv.org/abs/1710.03748) [[code]](https://github.com/openai/multiagent-competition)
* Learning with Opponent-Learning Awareness [[pdf]](https://arxiv.org/abs/1709.04326) [[code]](https://github.com/alshedivat/lola)
* Scalable trust-region method for deep reinforcement learning using Kronecker-factored approximation [[pdf]](https://arxiv.org/abs/1708.05144) [[code]](https://github.com/openai/baselines)
* Parameter Space Noise for Exploration [[pdf]](https://arxiv.org/abs/1706.01905) [[code]](https://github.com/openai/baselines)
* Proximal Policy Optimization Algorithms [[pdf]](https://arxiv.org/abs/1707.06347) [[code]](https://github.com/openai/baselines)
* Synthesizing Robust Adversarial Examples [[pdf]](https://arxiv.org/abs/1707.07397) 
* Hindsight Experience Replay [[pdf]](https://arxiv.org/abs/1707.01495)
* Teacher-Student Curriculum Learning [[pdf]](https://arxiv.org/abs/1707.00183) [[code]](https://github.com/tambetm/TSCL)
* Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments [[pdf]](https://arxiv.org/abs/1706.02275) [[code]](https://github.com/openai/multiagent-particle-envs)
* UCB Exploration via Q-Ensembles [[pdf]](https://arxiv.org/abs/1706.01502)
* Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World [[pdf]](https://arxiv.org/abs/1703.06907) 
* One-Shot Imitation Learning [[pdf]](https://arxiv.org/abs/1703.07326) 
* Equivalence Between Policy Gradients and Soft Q-Learning [[pdf]](https://arxiv.org/abs/1704.06440) 
* Stochastic Neural Networks for Hierarchical Reinforcement Learning [[pdf]](https://arxiv.org/abs/1704.03012) [[code]](https://github.com/florensacc/snn4hrl)
* Learning to Generate Reviews and Discovering Sentiment [[pdf]](https://arxiv.org/abs/1704.01444) [[code]](https://github.com/openai/generating-reviews-discovering-sentiment)
* Evolution Strategies as a Scalable Alternative to Reinforcement Learning [[pdf]](https://arxiv.org/abs/1703.03864) 
* Emergence of Grounded Compositional Language in Multi-Agent Populations [[pdf]](https://arxiv.org/abs/1703.04908) 
* Prediction and Control with Temporal Segment Models [[pdf]](https://arxiv.org/abs/1703.04070) 
* Third-Person Imitation Learning [[pdf]](https://arxiv.org/abs/1703.01703) [[code]](https://github.com/bstadie/third_person_im)
* PixelCNN++: Improving the PixelCNN with Discretized Logistic Mixture Likelihood and Other Modifications [[pdf]](https://arxiv.org/abs/1701.05517) [[code]](https://github.com/openai/pixel-cnn)

## 2016

* Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning [[pdf]](https://arxiv.org/abs/1611.04717) 
* On the Quantitative Analysis of Decoder-Based Generative Models [[pdf]](https://arxiv.org/abs/1611.04273) [[code]](https://github.com/tonywu95/eval_gen)
* A Connection between Generative Adversarial Networks, Inverse Reinforcement Learning, and Energy-Based Models [[pdf]](https://arxiv.org/abs/1611.03852)
* $\text{RL}^2$: Fast Reinforcement Learning via Slow Reinforcement Learning [[pdf]](https://arxiv.org/abs/1611.02779)
* Variational Lossy Autoencoder [[pdf]](https://arxiv.org/abs/1611.02731) 
* Extensions and Limitations of the Neural GPU [[pdf]](https://arxiv.org/abs/1611.00736) [[code]](https://github.com/openai/neural-gpu)
* Transfer from Simulation to Real World through Learning Deep Inverse Dynamics Model [[pdf]](https://arxiv.org/abs/1610.03518) 
* OpenAI Gym [[pdf]](https://arxiv.org/abs/1606.01540) 
* Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks [[pdf]](https://arxiv.org/abs/1602.07868) 
